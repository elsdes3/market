---
title: "Project Scope"
subtitle: "Intended use-case, data, analysis and suggested workflow"
---

## Understanding the Problem {#understanding-the-problem}
### Problem
The [Google Merchandise store](https://www.googlemerchandisestore.com/) is an e-commerce store that sells Google-branded products. Less than 5% of visitors make a purchase from the Google merchandise store on the Google Marketplace. So, a large number of visitors are not making a purchase. They are either just visiting the store once (their first and only visit) and leaving, or visiting multiple times and but not making a purchase on any of those visits. It goes without saying that customers, and not visitors alone, ensure the sustainability of an e-commerce business.

Considerable effort has been made by the web design team to build the store's website to attract site traffic and make a good impression on first-time visitors to the store. This effort should not go to waste. However, approximately [90% of purchases do not happen during an initial visit to an e-commerce website](https://www.optimizely.com/optimization-glossary/online-marketing/). Furthermore, [repeat customers spend 33% more with a brand than new customers do](https://www.freshlime.com/returning-customers-spend-33-more-than-other-customers/). Only approximately 20% of existing customers account for approximately 80% of future profits. Getting visitors to return to a site is important, but is possibly of equal or greater importance to an e-commerce business to have these visitors make a purchase on a return visit. This underscores the importance of getting visitors to make a purchase on a subsequent visit to the store.

But, it is not just sufficient to ensure return visits occur. This is of no use to a business since they can't grow customer revenue by relying visitors to return and make purchaes on their own volition. The visitor should be motivated between visits to return and make a purchase on one or more future visits, rather than just returning and browsing through the store as they did during a previous visit. Between August 1, 2016 and August 1, 2017, a little less than 2% of visitors made a purchase on a return visit to the Google merchandise store. One of the main reasons for visitors browsing an e-commerce store, rather than making a purchase, is because they are [comparson-shopping](https://www.myaccountingcourse.com/accounting-dictionary/comparison-shopping) across multiple such websites looking for the lowest price for the same or a very similar product.

In summary, it will help the Google Merchandise store grow their customer base and increase revenue if some of these first-time visitors who have

1. not made a purchase during their first visit
2. made a purchase during their first visit

to the store will make a purchase during a subsequent visit. In other words, it is desirable that first-time visitors to the store become customers or repeat customers.

### Impact of the Problem
If the business can find ways to reach out to (interact with) visitors to the store after their first visit, and provide promotions, shipping offers, etc., then this could be one way to motivate these visitors to make a purchase on a return visit to the store. If the Google merchandise store management company can reach out to these first-time visitors based on the characteristics of their first visit to the store and get them to make a purchase on a return visit then this can not only grow the business' customer base but also reduce the loss of customer revenue to a competitor.

[Alphabet is the parent company of Google](https://www.investopedia.com/articles/investing/081115/why-google-became-alphabet.asp), but [Robertson Marketing](https://www.robertsonmarketing.com/) is the company that [manages the Google Merchandise store](https://shop.googlemerchandisestore.com/store-policies/frequently-asked-questions/#aboutrobertson). The management company (Robertson Marketing) is impacted by the problem of low conversions or repeat customers among the pool of first-time visitors to the merchandise store and they would be interested in ways to turn such first-time visitors into one of the following

1. future customers ([converting visitors into customers](https://www.linkedin.com/pulse/visitors-customerswhich-one-do-you-want-cody-jensen), or [conversions](https://sherpablog.marketingsherpa.com/marketing/conversion-defined/))
2. repeat-customers ([customer retention](https://www.shopify.com/ca/blog/customer-retention-strategies))

### Task
The business (store management company, Robertson Marketing) has tasked its marketing team with growing

1. new customers (conversion)
2. repeat customers (getting customers to become repeat customers)

from the pool of first-time visitors to the store.

For obvious reasons, not all first-time visitors to the merchandise store are alike and reaching out to visitors is a costly process. With this mind, the marketing team would like to design an appropriate marketing campaign to help achive the business' objectives. With a strong preference to spend marketing funds (budget) wisely, the marketing team wants to interact with such first-time visitors through focused and relevant recommendations, reminders and other types of [marketing promotions](https://goldpromotion.com/marketing-vs-promotion-guidelines-for-success/) after their first visit to the store.

A logical approach to developing targeted promotions to grow customers or repeat customers is to offer a promotion based on a visitor's likelihood of making a purchase during a future visit to the merchandise store. Knowing this likelihood is useful in knowing which visitors the marketing team should be focused on and, subsequently, how much funding can be allocated to communicating with those visitors. Accordingly, the business can determine the type of promotion that should be offered. For example, a minimal discount could be offered to visitors with a high likelihood of making a future purchase. Similarly, more loyalty points, coupon giveaways or free shipping could be offered to visitors who are deemed less likely to make a future purchase from the store. These promotions can be offered after a visitor's first visit to the store with the aim of persuading them to make a purchase during a future visit.

### Current Approaches to Solving the Problem Today
Without knowing visitors' likelihood of making a purchase on a return visit, it is not possible to segment visitors into audience groups (eg. visitors with a high, medium or low likelihood of making a purchase on a return visit) after their first visit. If these groups and cohorts were known, the marketing team could test how they respond to marketing strategies. Naive random guesses at visitor likelihood groupings are costly and unlikely to get buy-in for funding requests from business management. Furthermore, a test and control cohort is needed within each group in order to quantitatively determine how each group responds to the chosen marketing campaign (i.e. these cohorts are needed to evaluate the performance of the campaign).

We will assume that the marketing team has not yet designed any approaches to address this problem. With this in mind, both the size of the audience groups and the size of these cohorts are currently completely unknown.

## Project Client and Definition of Objective
### Business Client
The client for this project is a marketing team responsible for managing marketing campaigns related to the Google merchandise store.

### Project Goal
This project exists to help the marketing team (client) interact with first-time visitors to the merchandise store, with the hopes of increasing the likelihood that these visitors will make a purchase (convert) or repeat-purchase during a future visit to the store. If this can be done, then it will help the team address the business' objectives of growing new and repeat customers as mentioned above.

The objective of this project is to increase the number of first-time visitors to the merchandise store who are converted into new or repeat customers.

## Actions that Need to be Taken
This project will facilitate develpoment of a proactive and targeted marketing strategy (eg. promotions) to grow new and repeat customers.

## Analysis
### Type of Analysis
We need to answer the important question: Which visitors should we prioritize through proactive marketing promotions. In orther words, we want to identify the visitors with a low, medium and high likelihood of making a purchase during a future (or return) visit to the store.

Since we want to intervene before a visitor's next visit to the store, we would predict the likelihood of every first-time visitor making a purchase during a subsequent visit. These predictions will used to create audience groups based on the likelihood of making a future purchase and prioritize and focus the marketing strategy per group.

The analysis to be performed here is a prediction task. We need to predict the likelihood (or propensity) of a purchase during a future visit.

### Format of Data
The analysis will be performed using machine learning (ML). A ML model will be trained using attributes (features) of the visitors' first visit and it will predict visitors' propensity to make a purchase on a return visit to the store. The best-performing trained ML model will be the one that can make this prediction with the highest accuracy or some other evaluation metric (this will be discussed later in the [Evaluation Metric](#evaluation-metric) sub-section below). This application of ML is called [propensity modeling](https://www.expressanalytics.com/blog/propensity-modeling-to-predict-customer-behavior-using-machine-learning/). The outcome to be predicted is binary (there are only two possible outcomes)

1. the visitor will make a purchase on a return visit
2. the visitor will not make a purchase on a return visit

In a ML context, this is a supervised learning problem. Attributes about the first visit made by visitors to the store site are retrieved from Google Analytics (GA) tracking data accumulated for visitors to the merchandise store. GA tracking code has been embeded in the store's website in order to anonymously track visitor interactions on the site. These attributes, or characteristics, of visitors' first visit are the independent variables or features in ML.

For the same visitors, the outcome (or label in ML) of return visits (whether a purchase on a return visit was made or not) is retrieved to determine if a purchase on a future visit was made by this visitor. This label is a forward-looking label since it references events from the future. By comparison, the features are from the past (historical data) since they reference attributes of the visitor's first visit to the store. Both features and label refer to the same visitor.

### Analysis Workflow Overview
With such a dataset of Google Analytics tracking data available for all visitors to the store between August 1, 2016 and August 1, 2017, a ML model will be trained to predict whether first-time visitors will make a purchase during a future (return) visit. The trained model then predicts probabilities (which are interpreted as likelihoods or propensities) for new visitors to make a purchase on a return (or future) visit to the store. These new visitors were not part of the model's training data. The predicted probabilities are then used to generate marketing audience groups (low, medium and high propensity) and test (or treatment) and control cohorts within each group as described above.

In summary the steps of such a workflow are

1. train ML model using historical data for first visit of visitors
   - this is the training data
2. use trained model to predict probabilities for first visit of visitors that are not part of the training data
   - this is the unseen data
3. use predicted probabilities to assign audience cohorts (test or control) to all visitors in the unseen data
4. build a brief profile of the visitors in the test cohort in unseen data
   - when building a marketing strategy, we are not allowed to look at the control cohort and so the profile will be required for the test cohort only
5. provide audience test cohorts and their associated profile summaries to the marketing team

### Timeframes for Study

1. In order to avoid [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)) (or [lookahead bias](https://www.investopedia.com/terms/l/lookaheadbias.asp)), the data splits are created in chronological order
   - training data
     - September 1, 2016 to December 31, 2016
   - validation data
     - January 1 - 31, 2017
   - test data
     - February 1 - 28, 2017
   - unseen data
     - March 1 - 31, 2017
2. We will assume that
   - the current date is March 1, 2017
   - ML model development can be performed between March 1 - 31, 2017
3. The marketing team is interested in growing new and repeat customers from visitors who made their first visit to the store during March 1 - 31, 2017 (unseen data). With this in mind, they want to
   - build their campaign around these visitors
   - launch their campaign on April 10, 2017
4. There are two constraints facing the client (marketing team)
   - the first visit data covering this period (unseen data) is only available on March 31, 2017 and this is close to the proposed campaign start date of April 10, 2017
   - designing a typical marketing campaign takes [1](https://www.makeitactive.com/faq/marketing-faqs/how-long-does-it-take-to-complete-a-marketing-plan) - [12](https://www.mktg-edge.com/how-long-does-it-take-to-create-a-marketing-plan/) weeks
   - campaign launch windows occur every month
     - campaigns can be launched on April 10, 2017, May 10, 2017, June 10, 2017, etc.

   With this in mind, the marketing team wants to start designing their campaign today (March 1, 2017). They do not want to wait until March 31, 2017 to receive recommended audience cohorts from the data science team and begin their campaign design. So, instead of waiting until March 31, 2017, the marketing team will start their campaign design using the audience cohorts recommended by the data science team using the test data split, which covers February 1 - 28, 2017.

   On March 31, 2017, the marketing team will receive the audience cohorts from the data science team for the visits who made their first visit to the store during March 1 - 31, 2017.    Between April 1, 2017 and April 9, 2017, the marketing team will start making adjustments to the campaign strategy by using the audience cohorts recommended by the data science team using the unseen data period (covering March 1 - 31, 2017). This will allow the marketing team to meet the proposed campaign start date of April 10, 2017.

   If the datascience team is unable to generate a sufficiently accurate ML model to meet the April 10, 2017 campaign launch date then they will need to improve their analysis in order to try to meet the next available launch date (May 10, 2017).

### Notes

1. Regarding ML labels (`y`)
   - as mentioned earlier, these are forward-looking labels
     - the ML features (`X`) are attributes of a visitor's first visit to the store
     - the ML labels (`y`) are the outcome (whether a purchase occurred or not) of that same visitor's future visits to the store
       - a purchase is allowed to occur during any future visit to the store, not just the next visit
   - in the period covering train, validation and test data splits, if a visitor has
     - made at least one purchase of a product during their return visit, then the label is set to `True` (or 1)
     - not made at least one purchase of a product during their return visit, then the label is set to `False` (or 0)
2. The data science team's recommended audience cohorts (test and control) of visitors will be accepted by the marketing team if the ML model's performance during evaluation (using the test data split) is better than that of a random model.

## How do Actions Follow From the Analysis
Based on visitors' predicted likelihood of making a purchase on a future visit, marketing audience test and control groups (cohorts) will be created. Each group will contain a visitor ID as well as all the attributes of the visitor's first visit that were used to predict the likelihood of a purchase during a return visit to the store.

These groups can be used by the marketing team to

1. design appropriate strategies that can be implemented during [activation](https://en.wikipedia.org/wiki/Marketing_activation)
2. estimate campaign costs

## Validation
### During Development
Development covers September 1, 2016 - February 28, 2017.

Since the current date is assumed to be March 1, 2017 and the training, validation and test data splits end no later than February 28, 2017, ML model predictions during validation (using validation split) and evaluation (using test split) can be scored before March 31, 2017.

Scoring is performed using evalaution metrics discussed in the [ML Evaluation Metric](#ml-evaluation-metric) sub-section below.

### During Production
Production covers March 1 - 31, 2017.

The model's predictions will be scored against the outcome (whether the visitor makes a purchase on their return/future visit to the store) at the end of the marketing campaign.

### Differences between Development and Production

1. During production, the predictions are used to inform a marketing audience cohorts (test and control). By definition, the marketing strategy will be applied to the test cohort. It will not be applied to the control group. With this in mind, during the production period (March 1 - 31, 2017), we can only evaluate the predictions of the trained ML model that are associated with first-time visitors to the store during this period if those visitors are placed in the control cohort.
2. As mentioned earlier, the marketing team will only accept the data science team's recommended audiente cohorts if the ML model outperforms a random model. At the same time, the data science team should also be checking for drift between attributes (features) of the first visit using the test split (development) and using the unseen data (production). If drift in features is observed outside a pre-defined threshold, then the data science team will need to repeat
   - ML model training using more training data (earlier start date than September 1, 2016)
   - evaluation using the test split
   - evaluation using the unseen data

   until drift is no longer observed. Feature drift checking will need to be done on April 1, 2017, before marketing audience visitor cohorts are given to the marketing team.

### Workflow in Production

1. The trained model will make predictions of probability (propensity or likelihood) for all first-time visitors to the store during March 1 - 31, 2017. Predictions are used to identify marketing audience test (or treatment) and control cohorts.
2. A marketing strategy is applied to all first-time visitors in the test group
3. Length of marketing promotion campaign is to be determined by marketing team
4. At the end of the marketing campaign
   - we will know which visitors who were predicted to make a purchase on a return visit did actually make a purchase
   - we can evaluate the predictions made by the trained ML model on first visits that occurred during March 1 - 31, 2017
   - we can calculate a suitable KPI for this project
     - KPI = number of purchases made by visitors in the test cohort - number of purchases made by visitors in the control cohort
       - if this KPI is larger than zero, then we have successfully grown our customer base, which was the objective of the task that the business has given to the marketing team
     - additional KPIs can also be considered

We mentioned that scoring predictions of first visits that occurred during the unseen data period (production) of March 1 - 31, 2017 cannot be performed until the end of the marketing campaign. This was also mentioned in the [during production](#during-production) sub-section above. It is worth emphasizing that until the end of the marketing campaign, we are unable to evalute the ML model's predictions of data during the unseen data period (production). For this reason, it is improtant to check for drift in ML features between the unseen data (March 1 - 31, 2017) and test data (February 1 - 28, 2017) before the predictions are made and the audience cohorts are generated.

Generally, marketing campaigns run for approximately three months but this [depends on numerous factors including](https://www.wfsbadvertising.com/blog/what-is-the-length-of-a-successful-marketing-campaign)

1. message
2. call to action ([CTA](https://www.investopedia.com/terms/c/call-action-cta.asp))
4. funds available (marketing budget)
4. expectations (desired uplift, etc.)

The duration, design and structure of the campaign will be determined by the marketing team starting on March 1, 2017 (today) and it will be finalized between April 1 - 9, 2019. On April 9, 2017, if it is determined that it is not feasible to design a campaign based on the audience cohorts recommended by the data science team (eg. cohorts are too large, etc.) then

1. the next available campaign launch window (May 10, 2017) will have to be targeted
2. the new unseen data (production) period will cover April 1 - 30, 2017
2. the datascience team will have to improve ML model performance between April 10 - 30, 2017

### ML Evaluation Metric
False negatives (tweets that should have been responded to but were predicted to not need a response) and false positives (tweets that did not need review by a team member but were predicted as requiring a review) are the most important types of errors. So the [candidate metrics to be used to assess ML model performance](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/) are

1. F1-score (if false negatives and false positives are equally important)
2. F2-score (if false negatives are more important)
3. F0.5-score (if false positives are more important)

For the current predicton task, there are two possible outcomes indicate whether a visitor did or did not make a purchase on a return visit to the store and these are

1. actual
   - is the true outcome
   - this is known after a visitor's first visit to the store
   - this indicates that action that the marketing team should have taken
2. predicted
   - is the predicted outcome
   - this is predicted after the visitor's first visit to the store
   - this indicates that action that the marketing team was predicted to have taken

The four possible ML prediction scenarios are listed below for the prediction of the outcome [whether a first-time visitor will, or will not, make a purchase on a return (future) visit to the merchandise store]

1. TP: actual = makes purchase on return visit, predicted = makes purchase on return visit
   - predicted marketing strategy matches what should be the actual marketing strategy
2. TN: actual = does not make purchase on return visit, predicted = does not make purchase on return visit
   - predicted marketing strategy matches what should be the actual marketing strategy
3. FN: actual = makes purchase on return visit, predicted = does not make purchase on return visit
   - predicted marketing strategy
     - predicted to offer minimal promotion
   - actual marketing strategy
     - actually should have offered a stronger promotion
       - eg. more loyalty points, more frequent free/shipping, etc.
   - these errors in prediction lead to missed opportunities to correctly target first-time visitors since the predicted promotion offered is an underestimate of the true promotion that the team should have offered to these visitors
   - these errors lead to underspending on promotions to first-time visitors who are likely to benefit from them
4. FP: actual = does not make purchase on return visit, predicted = makes purchase on return visit
   - predicted marketing strategy
     - predicted to offer a stronger promotion
   - actual marketing strategy
     - actually should have offered minimal promotion
   - these errors lead to overspending on promotions to first-time visitors who are not likely to benefit from them
   - this is the most expensive type of prediction error
   - this scenario must be avoided

Since FP (false positives) are more costly than FN (false negatives), the scoring metric chosen to evaluate predictions made using the ML model is [F0.5-score](https://machinelearningmastery.com/fbeta-measure-for-machine-learning/).

## Data
An important factor that is driving propensity modeling in marketing is the need to do more with [first-party customer data](https://signal.co/resources/first-party-data/#whydoesitmatter). This is data that comes directly from the customer and not from third-party sources. For marketing use-cases, effective propensity models use customer attributes from online and offline first-party data sources, including site analytics (online) and CRM (offline) data.

Here, we have access to online data only Google Analytics tracking data (see the [dataset](https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data) and its [documentation](https://support.google.com/analytics/answer/3437719?hl=en)). This will be used to build a ML model to predict visitors' propensity to make a purchase during a future visit to the store.

Visit data for the merchandise store is available for the period of August 1, 2016 to August 1, 2017. This data provides information such as

1. visitor ID
2. visit `date`
3. vist `datetime`
4. actions performed during visit
   - add to cart
   - remove from cart
   - make purchase
   - view product details
   - etc.
5. total time spent viewing pages during each visit
6. etc.

## Analysis Notebooks
1. Get data and EDA Part 1
   - connect to raw visit data generated by Google Analytics tracking embedded in the merchandise store's site
     - data is stored as [Google BigQuery public dataset](https://cloud.google.com/bigquery/public-data)
     - use Python client to connect to dataset
     - get overview of the columns in the raw visit data
   - understand underlying patterns and stats about the visit-level data
   - EDA part 1/2
   - `01_get_data.ipynb`
2. EDA Part 2
   - EDA part 2/2
   - `02_eda.ipynb`
3. Transform data
   - `03_transform.ipynb`
   - extract the first visit per visitor (features, or `X`) and align with whether they made a purchase on a return (future) visit to the store (labels, or `y`)
4. Baseline model development
   - develop a baseline model to predict probability of purchase during future visit
     - this will be fast to train and will demonstrate the end-to-end project workflow, but will likely be over-simplified and so will underperform relative to a ML-based approach
   - `04_development.ipynb`
5. ML model development
   - repeat baseline model development, but use a ML model instead
   - `05_dev_v2.ipynb`

## Limitations
### Business Use Case
The analysis implemented here is only possible if Google Analytics tracking is embedded into an e-commerce website. Guides for embedding GA tracking code are documented below

1. [chartio blog post](https://chartio.com/learn/marketing-analytics/how-to-add-google-analytics-tracking-to-a-website/)
2. [Google Support documentation](https://support.google.com/analytics/answer/9304153?hl=en)

For the current use-case, this was already done for the Google Merchandise store's website and so valuable tracking data could be collected and used. However, if such a solution is to be adopted for other digital marketplaces, then the Google Analytics tracking code must be embedded into those websites.

### Data
1. The analytics dataset used in this project is based on a version of [Google Analytics (GA360)](https://marketingplatform.google.com/about/analytics-360/features/) that is [deprecated as of July 1 2023 or 2024](https://support.google.com/analytics/answer/11583528?hl=en).

### Others
For other limitations, please see the **Limitations** section in each notebook.

## Assumptions
### Business Use Case
1. For visitors who made a purchase on a return visit, we will include those who could have bought on their first as well. These are repeat customers, who we have assumed are one of the two types of visitors that we want to grow. For this reason, we will include their visits in the data.
2. The marketing team has does not have a preliminary idea as to the size of the audience groups (low, medium, high likelihood or propensity to make a purchase on a return visit) or cohorts and the strategy they will deploy as part of a campaign. As such, they have not yet designed any approaches to address this problem.
3. Deployment-related assumptions (see point 4. in [Timeframes for Study](#timeframes-for-study))
   - we have assumed that the current date is March 1, 2017
   - we have assumed that a trained ML model will make predictions for all first-time visitors to the store between March 1 - 31, 2017

For other assumptions, please see the **Assumptions** section in each notebook.
